###############
# Description #
###############

# This script will be divided into several sections, following the same structure as the Rmd/report file:

# 1. Data Adquisition: The project will start by downloading the data set using the script provided by HarvardX.
# 2. Data Exploration: Once all the data is obtained, I will proceed with the exploratory data analysis.
# 3. Modeling: With the insights we gain on step 2, we will start to make the recommendation system model.
# 4. Model Testing: Once we define our final model using our training data set, we will run it on our test data set.



###############################
# Section 1: Data Adquisition #
###############################

#The first section of this script contains the code provided to generate the data sets to be used on this project.
#When we load the code, we will have both the Tidyverse and Caret libraries loaded.

#The code section below might take several minutes to run depending on your system characteristics and internet speed.
#To facilitate the reproduction of the results we will keep all the objects generated within the session of this script.



#######################################################
# Create edx set, validation set, and submission file #
#######################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)



################################
# Preliminary Data Exploration #
################################

# We will check the structure of the two datasets generated by the script using the str() function

str(edx)
str(validation)


###############################
# Section 2: Data Exploration #
###############################

#As we saw on the Preliminary Data Exploration, both data sets follow the same structure.
#We can corroborate that looking at the first 6 entries.

head(edx)
head(validation)

#We will then check how many unique movies and how many unique users we have on both data sets.

edx %>% 
  summarize(n_users = n_distinct(userId),
          n_movies = n_distinct(movieId))

validation %>% 
  summarize(n_users = n_distinct(userId),
          n_movies = n_distinct(movieId))

#Now we will check if every user rated every movie multiplying the number of users by the number of movies
#to then compare the result with the data set size.

edx_users_and_movies <- edx %>% 
                          summarize(n_users = n_distinct(userId),
                          n_movies = n_distinct(movieId))

(edx_users_and_movies$n_users * edx_users_and_movies$n_movies) == nrow(edx)

val_users_and_movies <- validation %>% 
                          summarize(n_users = n_distinct(userId),
                          n_movies = n_distinct(movieId))

(val_users_and_movies$n_users * val_users_and_movies$n_movies) == nrow(validation)

#We will check how the data distribution is for the movie rating frequency and user rating frequency on both data sets

#Edx Movie Rating Frequency lookup

edx %>%
  count(movieId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  labs(x = "Movie Ratings (Log10 Scale)", y = "Count", title = "Movie Rating Frequency - edX Data Set")

#Validation Movie Rating Frequency lookup

validation %>% 
  count(movieId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  labs(x = "Movie Ratings (Log10 Scale)", y = "Count", title = "Movie Rating Frequency - Validation Data Set")

#Edx Movie Rating Frequency lookup

edx %>% 
  count(userId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 30, color = "black") + 
  scale_x_log10() +
  labs(x = "User Ratings (Log10 Scale)", y = "Count", title = "User Rating Frequency - edX Data Set")

#Edx Movie Rating Frequency lookup

validation %>% 
  count(userId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 30, color = "black") +
  scale_x_log10() +
  labs(x = "User Ratings (Log10 Scale)", y = "Count", title = "User Rating Frequency - Validation Data Set")

#Lastly, we will look at the rating distribution on both data sets

edx %>%
mutate(rating = as.factor(rating)) %>%
  count(rating) %>%
  ggplot(aes(x = rating, y = n/1000)) +
  geom_col(color = "black") +
  labs(x = "Ratings", y = "Count in Thousands", title = "Movie Rating Frequency - edX Data Set")  

validation %>%
  mutate(rating = as.factor(rating)) %>%
  count(rating) %>%
  ggplot(aes(x = rating, y = n/1000)) +
  geom_col(color = "black") +
  labs(x = "Ratings", y = "Count in Thousands", title = "Movie Rating Frequency - Validation Data Set")  


#######################
# Section 3: Modeling #
#######################

#We will now define a function for the formula of the RMSE

RMSE <- function(true_ratings, predicted_ratings){
        sqrt(mean((true_ratings - predicted_ratings)^2))
        }
#We will start with a simple Most-Common Rating Model

mc_rmse <- RMSE(edx$rating, 4) #I used mc for "most-common"
mc_rmse

#Next, we will create an object to store our results

rmse_results <- data_frame(Model = "Most-Common Rating Model", RMSE = mc_rmse)
rmse_results %>% knitr::kable()

#Now we will try using the average rating for our prediction

mu <- mean(edx$rating)
mu

avg_rating_rmse <- RMSE(edx$rating, mu)
avg_rating_rmse

#And we will save the result into our chart

rmse_results <- bind_rows(rmse_results,
                          data_frame(Model ="Average Rating Model",  
                                     RMSE = avg_rating_rmse))
rmse_results %>% knitr::kable()

#Next, we will include a movie bias term, we will compute it and see its distribution

movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))

movie_avgs %>% ggplot(aes(b_i)) +
  geom_histogram(bins = 10, color = "black") + 
  labs(x = "Movie Bias Values", y = "Count", title = "Movie Bias Distribution")

#Now we will see the results of our new model

predicted_ratings <- mu + edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)

movie_bias_rmse <- RMSE(predicted_ratings, edx$rating)
movie_bias_rmse
rmse_results <- bind_rows(rmse_results,
                          data_frame(Model ="Movie Bias Model",  
                                     RMSE = movie_bias_rmse))
rmse_results %>% knitr::kable()

#Now, we will add a user bias into our existing model to create a new one

edx %>% 
  group_by(userId) %>% 
  filter(n()>=100) %>%
  summarize(b_u = mean(rating)) %>%
  ggplot(aes(b_u)) + 
  geom_histogram(bins = 30, color = "black")

#And then, compute our new user bias term

user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

#To then use it as a new predictor into our model

predicted_ratings <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

movie_user_bias_rmse <- RMSE(predicted_ratings, edx$rating)
movie_user_bias_rmse

rmse_results <- bind_rows(rmse_results,
                          data_frame(Model="Movie + User Bias Model",  
                                     RMSE = movie_user_bias_rmse))
rmse_results %>% knitr::kable()




############################
# Section 4: Model Testing #
############################

#We will start by running our first Most-Common Rating Model with the validation data set

val_mc_rmse <- RMSE(validation$rating, 4)
val_mc_rmse

#Then, we will store it into a new chart

val_rmse_results <- data_frame(Model = "Most-Common Rating Model", RMSE = val_mc_rmse)
val_rmse_results %>% knitr::kable()

#Next, we will run the Average Rating Model with the validation data set

val_avg_rating_rmse <- RMSE(validation$rating, mu)
val_avg_rating_rmse

#And store our results

val_rmse_results <- bind_rows(val_rmse_results,
                          data_frame(Model ="Average Rating Model",  
                                     RMSE = val_avg_rating_rmse))
val_rmse_results %>% knitr::kable()

#Next, we will run our Movie Bias Model with the validation data set

val_movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))

val_predicted_ratings <- mu + validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  pull(b_i)

val_movie_bias_rmse <- RMSE(val_predicted_ratings, validation$rating)
val_movie_bias_rmse

#And store our results

val_rmse_results <- bind_rows(val_rmse_results,
                          data_frame(Model ="Movie Bias Model",  
                                     RMSE = val_movie_bias_rmse))
val_rmse_results %>% knitr::kable()

#Lastly, we will now run our Movie and User Bias Model with the validation data set

val_user_avgs <- edx %>% 
  left_join(val_movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

val_predicted_ratings <- validation %>% 
  left_join(val_movie_avgs, by='movieId') %>%
  left_join(val_user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

val_movie_user_bias_rmse <- RMSE(val_predicted_ratings, validation$rating)
val_movie_user_bias_rmse

#And store our results

val_rmse_results <- bind_rows(val_rmse_results,
                          data_frame(Model="Movie + User Bias Model",  
                                     RMSE = val_movie_user_bias_rmse))
val_rmse_results %>% knitr::kable()




##############
# Conclusion #
##############

#Finally, we will now see our results on our training set compared to the ones obtained on the test set

rmse_results %>% knitr::kable()
val_rmse_results %>% knitr::kable()

